static uint64_t domain_pgd_maddr(struct domain *d, unsigned int nr_pt_levels)
{
    struct domain_iommu *hd = dom_iommu(d);
    uint64_t pgd_maddr;
    unsigned int agaw;

    ASSERT(spin_is_locked(&hd->arch.mapping_lock));

    if ( iommu_use_hap_pt(d) )
    {
        pagetable_t pgt = p2m_get_pagetable(p2m_get_hostp2m(d));

        return pagetable_get_paddr(pgt);
    }

    if ( !hd->arch.vtd.pgd_maddr )
    {
        /* Ensure we have pagetables allocated down to leaf PTE. */
        addr_to_dma_page_maddr(d, 0, 1);

        if ( !hd->arch.vtd.pgd_maddr )
            return 0;
    }

    pgd_maddr = hd->arch.vtd.pgd_maddr;

    /* Skip top levels of page tables for 2- and 3-level DRHDs. */
    for ( agaw = level_to_agaw(4);
          agaw != level_to_agaw(nr_pt_levels);
          agaw-- )
    {
        const struct dma_pte *p = map_vtd_domain_page(pgd_maddr);

        pgd_maddr = dma_pte_addr(*p);
        unmap_vtd_domain_page(p);
        if ( !pgd_maddr )
            return 0;
    }

    return pgd_maddr;
}
